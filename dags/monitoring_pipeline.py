"""
DAG Airflow pour le monitoring automatique et dÃ©tection de drift
"""
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.operators.bash import BashOperator
from datetime import datetime, timedelta

# Configuration
default_args = {
    'owner': 'mlops',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email_on_failure': True,
    'email': ['your-email@example.com'],
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

# DAG de monitoring
dag = DAG(
    'monitoring_drift_detection',
    default_args=default_args,
    description='Pipeline de monitoring et dÃ©tection de drift',
    schedule_interval='@daily',  # Tous les jours
    catchup=False,
    tags=['mlops', 'monitoring', 'drift']
)

# Task 1: ExÃ©cuter le monitoring
run_monitoring = BashOperator(
    task_id='run_drift_detection',
    bash_command='cd /app && python ./src/monitoring/monitor.py',
    dag=dag
)

# Task 2: VÃ©rifier si drift dÃ©tectÃ©
def check_drift_alerts(**context):
    """VÃ©rifie si des alertes de drift ont Ã©tÃ© gÃ©nÃ©rÃ©es"""
    import os
    import json
    
    alert_file = '/app/logs/drift_alerts.json'
    
    if not os.path.exists(alert_file):
        print("âœ… Aucune alerte de drift")
        return False
    
    # Lire les alertes rÃ©centes (derniÃ¨res 24h)
    from datetime import datetime, timedelta
    
    with open(alert_file, 'r') as f:
        alerts = [json.loads(line) for line in f]
    
    recent_alerts = [
        alert for alert in alerts
        if datetime.fromisoformat(alert['timestamp']) > datetime.now() - timedelta(days=1)
    ]
    
    if recent_alerts:
        print(f"ğŸš¨ {len(recent_alerts)} alerte(s) dÃ©tectÃ©e(s) dans les derniÃ¨res 24h")
        return True
    else:
        print("âœ… Pas d'alerte rÃ©cente")
        return False

check_drift = PythonOperator(
    task_id='check_drift_alerts',
    python_callable=check_drift_alerts,
    dag=dag
)

# Task 3: DÃ©clencher rÃ©entraÃ®nement si drift dÃ©tectÃ©
def trigger_retraining_if_needed(**context):
    """DÃ©clenche le rÃ©entraÃ®nement si drift dÃ©tectÃ©"""
    ti = context['ti']
    drift_detected = ti.xcom_pull(task_ids='check_drift_alerts')
    
    if drift_detected:
        print("ğŸ”„ Drift dÃ©tectÃ©! DÃ©clenchement du rÃ©entraÃ®nement...")
        
        # DÃ©clencher le DAG de training
        from airflow.operators.trigger_dagrun import TriggerDagRunOperator
        
        # Note: Cette partie nÃ©cessite d'Ãªtre adaptÃ©e selon ta config
        print("âš ï¸ RÃ©entraÃ®nement Ã  dÃ©clencher manuellement ou via API Airflow")
        
        return "retraining_needed"
    else:
        print("âœ… Pas de rÃ©entraÃ®nement nÃ©cessaire")
        return "no_action"

trigger_retraining = PythonOperator(
    task_id='trigger_retraining_if_needed',
    python_callable=trigger_retraining_if_needed,
    dag=dag
)

# Task 4: GÃ©nÃ©rer rapport de monitoring
def generate_monitoring_report(**context):
    """GÃ©nÃ¨re un rapport quotidien de monitoring"""
    import json
    from datetime import datetime
    
    report = {
        'date': datetime.now().isoformat(),
        'monitoring_executed': True,
        'drift_detection_run': True,
        'alerts_checked': True
    }
    
    # Sauvegarder le rapport
    with open('/app/logs/monitoring_daily_report.json', 'w') as f:
        json.dump(report, f, indent=2)
    
    print("ğŸ“Š Rapport de monitoring gÃ©nÃ©rÃ©")

generate_report = PythonOperator(
    task_id='generate_monitoring_report',
    python_callable=generate_monitoring_report,
    dag=dag
)

# Workflow
run_monitoring >> check_drift >> trigger_retraining >> generate_report